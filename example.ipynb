{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_encoder.encoder import ModelEncoder\n",
    "from model_encoder.operations import *\n",
    "from model_encoder.data_loaders import load_cifar\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "Here, we'll walk through the process of building a model via model encoding. In this example, we'll create something reminiscient of a ResNet and train it on CIFAR10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Available Operations\n",
    "First, we need to establish the available operations for use within the model. We'll use some of the prepackaged operations in model_encoder.operations, but we'll also define two custom ones. To build an operation, we need to pass `build_operation` three things:\n",
    "\n",
    "* `name`: a string that uniquely refers to the operation\n",
    "* `function`: An initialization function for the operation. This takes the form of some function f(c) that when supplied a channel size returns an initialized PyTorch module.\n",
    "* `mod`: The dimensionality modification factors. These describe how the operation affects the channel, height, and width dimensions of tensors flowing through it, and we supply it as tuple in the format `[C,H,W]`.\n",
    "<br><br>\n",
    "Our first operation, `Reducer`, will double channel dimensions and halve spatial dimensions, whereas our second, `Scaler`, will simply double channel dimensions.\n",
    "<br><br>\n",
    "Once we have all the operations we need, we'll pass that list into `build_operation_set`, which shows us a little reference to our operation set for use later when we're building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i |      Name       | *C  | *H  | *W  |\n",
      "----------------------------------------\n",
      " 0 | Identity        |  1  |  1  |  1  |\n",
      " 1 | ReLU            |  1  |  1  |  1  |\n",
      " 2 | BatchNorm       |  1  |  1  |  1  |\n",
      " 3 | Conv3x3         |  1  |  1  |  1  |\n",
      " 4 | Reducer         |  1  |  2  | 0.5 |\n",
      " 5 | Scaler          |  1  |  2  |  1  |\n"
     ]
    }
   ],
   "source": [
    "Reducer = build_operation(name='Reducer', \n",
    "                          function=lambda c: conv2d(c, c * 2, k=3, s=2), \n",
    "                          mod=[2, .5, .5])\n",
    "Scaler  = build_operation(name='Scaler',  \n",
    "                          function=lambda c: conv2d(c, c * 2, k=1), \n",
    "                          mod=[2, 1, 1])\n",
    "\n",
    "operation_set = build_operation_set(\n",
    "    Identity, \n",
    "    ReLU, \n",
    "    BatchNorm,\n",
    "    Conv3x3,\n",
    "    Reducer,\n",
    "    Scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Some Cells\n",
    "Next, we'll create some cells to use in our model. The easiest way to create cells are via dictionaries, where the keys are tuples referring to edges in the cell, and the values are the list of operations that exist along that edge. For example, `(0,1): ['Identity', 'Conv3x3']` refers to the edge between Node 0 and Node 1, and places both an Identity and 3x3 Convolution along that edge.\n",
    "<br><br>\n",
    "We'll create three cells, an upscaling cell to upscale the input data to a larger channel dimension, a normal cell, and a reduction cell. Notice that we ensure that each cell has the same number of nodes (7), as necessitated by the largest cell, the reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaling_cell = {\n",
    "    (0,1): ['Scaler'],\n",
    "    (1,2): ['Scaler'],\n",
    "    (2,3): ['Scaler'],\n",
    "    (3,4): ['Scaler'],\n",
    "    (4,7): ['Scaler'],\n",
    "}\n",
    "\n",
    "normal_cell = {\n",
    "    (0,2): ['Conv3x3'],\n",
    "    (2,3): ['BatchNorm'],\n",
    "    (3,4): ['ReLU'],\n",
    "    (4,5): ['Conv3x3'],\n",
    "    (5,6): ['BatchNorm'],\n",
    "    (6,7): ['ReLU'],\n",
    "    (0,7): ['Identity'],\n",
    "}\n",
    "\n",
    "reduction_cell = {\n",
    "    (0,1): ['Reducer'],\n",
    "    (1,2): ['Conv3x3'],\n",
    "    (2,3): ['BatchNorm'],\n",
    "    (3,4): ['ReLU'],\n",
    "    (4,5): ['Conv3x3'],\n",
    "    (5,6): ['BatchNorm'],\n",
    "    (6,7): ['ReLU'],\n",
    "    (1,7): ['Identity']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Model\n",
    "Finally, we can build our model. The easiest way to do this is via a model structure dictionary, where the keys are cell number and the values are the cell dictionaries as described above. Once we've created the structure dictionary, we can pass it to `ModelEncoder.adj_from_dict` along with our operation set to create the adjacency matrix for this particular structure. Alternatively, we could have just hand-written the 4D adjacency, but that'd be a pain. \n",
    "<br><br>\n",
    "We'll also need to define an output function for our model, which defines how the function that takes the last cell's output and transforms it into the shape we want. The operations module contains sample Classifier and Regression functions, so for our purposes we'll use the Classifier. To do this, we pass the Classifier into `build_output` and specify the length of the output vector we need. For CIFAR10, we have 10 classes, so we'll choose 10 for our output size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = {\n",
    "    0: upscaling_cell,\n",
    "    1: normal_cell,\n",
    "    2: normal_cell,\n",
    "    3: reduction_cell,\n",
    "    4: normal_cell,\n",
    "    5: normal_cell,\n",
    "    6: reduction_cell,\n",
    "    7: normal_cell,\n",
    "    8: normal_cell\n",
    "}\n",
    "adj = ModelEncoder.adj_from_dict(model_structure, operation_set)\n",
    "output_function = build_output(Classifier, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got everything we need to create our model, so we'll load the data from `model_encoder.data_loaders.load_cifar` and build our model. The ModelEncoder constructor needs five arguments:\n",
    "* `input_dim`: the dimensionality of each tensor input. In our case, it's `[64,3,32,32]`\n",
    "* `adjacency`: the adjacency matrix of the model\n",
    "* `operation_set`: the set of operations referred to by the adjacency matrix\n",
    "* `output_function`: the output function of the model\n",
    "* `device`: the torch.device to put the model onto\n",
    "<br><br>\n",
    "\n",
    "The ModelEncoder will dynamically compute all the tensor dimensionalities throughout the model and intialize parameters accordingly. If the tensor dimensions cannot align (say, for example, an Identity and an Upscaler that share origin and target nodes) then ModelEncoder will raise an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "(train_loader, test_loader), dim = load_cifar(batch_size=64)\n",
    "me = ModelEncoder(input_dim=dim,\n",
    "                  adjacency=adj,\n",
    "                  operation_set=operation_set,\n",
    "                  output_function=output_function,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training and Testing Functions\n",
    "These are just slightly modified versions of the train and test functions from PyTorch's [CIFAR10 Tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader, device):\n",
    "    running_loss = 0.0\n",
    "    dl_len = len(dataloader)\n",
    "    for i, (x,y) in enumerate(dataloader, 0):\n",
    "        if i%10==0 or i+1==dl_len:\n",
    "            print(\"\\r  Train Batch: {:>4}/{:<4}\".format(i+1, dl_len), end=\"\")\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "def test(model, dataloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    print(\"| Test Accuracy: {:.2f}%\".format(correct/len(dataloader.dataset)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "And now we can train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== EPOCH 0 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 48.30%\n",
      "== EPOCH 1 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 52.49%\n",
      "== EPOCH 2 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 55.27%\n",
      "== EPOCH 3 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 57.87%\n",
      "== EPOCH 4 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 58.49%\n",
      "== EPOCH 5 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 60.40%\n",
      "== EPOCH 6 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 60.52%\n",
      "== EPOCH 7 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 62.00%\n",
      "== EPOCH 8 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 62.22%\n",
      "== EPOCH 9 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 62.68%\n",
      "== EPOCH 10 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 62.69%\n",
      "== EPOCH 11 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 63.28%\n",
      "== EPOCH 12 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 63.50%\n",
      "== EPOCH 13 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 63.77%\n",
      "== EPOCH 14 ==\n",
      "  Train Batch:  782/782 | Test Accuracy: 63.70%\n",
      "== EPOCH 15 ==\n",
      "  Train Batch:  782/782 "
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(me.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "for epoch in range(epochs):\n",
    "    print(\"== EPOCH {} ==\".format(epoch))\n",
    "    train(me, optimizer, criterion, train_loader, device)\n",
    "    test(me, test_loader, device)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
